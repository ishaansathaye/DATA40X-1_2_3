{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 5 - Ishaan Sathaye"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our dataset consists of clinical data from patients who entered the hospital complaining of chest pain (“angina”) during exercise. The information collected includes:\n",
    "\n",
    "- age : Age of the patient\n",
    "\n",
    "- sex : Sex of the patient\n",
    "\n",
    "- cp : Chest Pain type\n",
    "    - Value 1: typical angina\n",
    "    - Value 2: atypical angina\n",
    "    - Value 3: non-anginal pain\n",
    "    - Value 4: asymptomatic\n",
    "\n",
    "- trtbps : resting blood pressure (in mm Hg)\n",
    "\n",
    "- chol : cholesteral in mg/dl fetched via BMI sensor\n",
    "\n",
    "- restecg : resting electrocardiographic results\n",
    "    - Value 0: normal\n",
    "    - Value 1: having ST-T wave abnormality (T wave inversions and/or ST elevation or depression of > 0.05 mV)\n",
    "    - Value 2: showing probable or definite left ventricular hypertrophy by Estes’ criteria\n",
    "- thalach : maximum heart rate achieved during exercise\n",
    "\n",
    "- output : the doctor’s diagnosis of whether the patient is at risk for a heart attack\n",
    "    - 0 = not at risk of heart attack\n",
    "    - 1 = at risk of heart attack\n",
    "\n",
    "A copy of the dataset that has been cleaned, dummified, and standardized for you is found at https://www.dropbox.com/s/jpnyx41u7wpa41m/heart_attack_clean.csv?dl=1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section A\n",
    "\n",
    "1. Provide the gradient function derivation for SVC.\n",
    "    - $l(w, c) = \\sum_{i=1}^{n} max(0, 1 - y_i*\\hat{y_i}) + \\lambda||w||^2_2$\n",
    "    - Expand:\n",
    "        - $l(w, c) = \\sum_{i=1}^{n} max(0, 1 - y_i*(w^Tx_i + c)) + \\lambda||w||^2_2$\n",
    "    - Derivative with respect to w:\n",
    "        - $\\nabla_w l(w, c) = -y_i*x_i$ if $y_i*(w^Tx_i + c) < 1$\n",
    "        - $\\nabla_w l(w, c) = 0$ if $y_i*(w^Tx_i + c) >= 1$\n",
    "    - Derivative with respect to c:\n",
    "        - $\\nabla_c l(w, c) = -y_i$ if $y_i*(w^Tx_i + c) < 1$\n",
    "        - $\\nabla_c l(w, c) = 0$ if $y_i*(w^Tx_i + c) >= 1$\n",
    "    - Regularization term:\n",
    "        - $\\nabla_w \\lambda||w||^2_2 = 2\\lambda w$\n",
    "        - $\\nabla_c \\lambda||w||^2_2 = 0$\n",
    "    - $\\nabla_w l(w, c) = \\sum_{i=1}^{n} -y_i*x_i + 2\\lambda w$ for $iy_i*(w^Tx_i + c) < 1$\n",
    "    - $\\nabla_c l(w, c) = \\sum_{i=1}^{n} -y_i$ for $iy_i*(w^Tx_i + c) < 1$\n",
    "\n",
    "2. Provide the derivation of the beta equations for LDA.\n",
    "    - $p(x) = p_1*\\frac{1}{\\sqrt{2\\pi\\sigma^2}}e^{-\\frac{(x-\\mu_1)^2}{2\\sigma^2}}*(1-p_1)*\\frac{1}{\\sqrt{2\\pi\\sigma^2}}e^{-\\frac{(x-\\mu_0)^2}{2\\sigma^2}}$\n",
    "    - Log-Likelihood Ratio:\n",
    "        - $log(\\frac{p(x|y=1)}{p(x|y=0)}) = log(\\frac{p_1}{1-p_1}) - \\frac{(x-\\mu_1)^2}{2\\sigma^2} + \\frac{(x-\\mu_0)^2}{2\\sigma^2}$\n",
    "    - $z_i = log(\\frac{p_1}{1-p_1}) - \\frac{(\\mu_0^2-\\mu_1^2)}{2\\sigma^2} + \\frac{(\\mu_0-\\mu_1)}{2\\sigma^2}*x_i$\n",
    "    - $z_i = \\beta_0 + \\beta_1*x_i$\n",
    "    - Convert to multivariate form:\n",
    "        - $z = \\beta^Tx$\n",
    "    - $\\hat{\\beta} = \\hat{\\Sigma}^{-1}(\\bar{X_1} - \\bar{X_0})$\n",
    "    - $\\hat{\\beta_0} = log(\\frac{p_1}{1-p_1}) - \\frac{1}{2}(\\bar{X_1}^T\\hat{\\Sigma}^{-1}\\bar{X_1} - \\bar{X_0}^T\\hat{\\Sigma}^{-1}\\bar{X_0})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Consider the small example data:\n",
    "    - cholesterol: [192, 233, 236, 237, 250, 294, 354, 410]\n",
    "    - at-risk category: [0, 0, 1, 1, 0, 1, 1, 1]\n",
    "\n",
    "3. All three models result in a decision boundary, $X\\beta = 0$. Find the $\\beta$ values from the data above for all three models. How similar were the results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression: beta_0 = -12.340540456260143, beta_1 = 0.0515573330459061\n",
      "SVC: beta_0 = -4.7647058823473305, beta_1 = 0.019607843137204345\n",
      "LDA: beta_0 = -4.7274599147154746, beta_1 = 0.019722460611752507\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Data\n",
    "cholesterol = np.array([192, 233, 236, 237, 250, 294, 354, 410])\n",
    "at_risk = np.array([0, 0, 1, 1, 0, 1, 1, 1])\n",
    "X = cholesterol.reshape(-1, 1)\n",
    "y = at_risk\n",
    "\n",
    "# Logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X, y)\n",
    "beta_0 = log_reg.intercept_[0]\n",
    "beta_1 = log_reg.coef_[0][0]\n",
    "print(f\"Logistic regression: beta_0 = {beta_0}, beta_1 = {beta_1}\")\n",
    "\n",
    "# SVC\n",
    "from sklearn.svm import SVC\n",
    "svm = SVC(kernel=\"linear\")\n",
    "svm.fit(X, y)\n",
    "beta_0 = svm.intercept_[0]\n",
    "beta_1 = svm.coef_[0][0]\n",
    "print(f\"SVC: beta_0 = {beta_0}, beta_1 = {beta_1}\")\n",
    "\n",
    "# LDA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "lda.fit(X, y)\n",
    "beta_0 = lda.intercept_[0]\n",
    "beta_1 = lda.coef_[0][0]\n",
    "print(f\"LDA: beta_0 = {beta_0}, beta_1 = {beta_1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVC and LDA were the most similar results with their $\\beta$ values being [-4.76, 0.0196] and [-4.72, 0.0197] respectively. Logistic Regression was the most different with a $\\beta$ value of [-12.3, 0.05]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. For the three classifiers, find the actual decision boundary; i.e., the cholesterol value for which $X\\beta = 0$. Give some intuition for why certain models have higher cutoffs than others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression cutoff: 239.35567895399586\n",
      "SVC cutoff: 243.0000000003404\n",
      "LDA cutoff: 239.6992955279833\n"
     ]
    }
   ],
   "source": [
    "# Logistic regression\n",
    "beta_0 = log_reg.intercept_[0]\n",
    "beta_1 = log_reg.coef_[0][0]\n",
    "lr_cutoff = -beta_0 / beta_1\n",
    "\n",
    "# SVC\n",
    "beta_0 = svm.intercept_[0]\n",
    "beta_1 = svm.coef_[0][0]\n",
    "svm_cutoff = -beta_0 / beta_1\n",
    "\n",
    "# LDA\n",
    "beta_0 = lda.intercept_[0]\n",
    "beta_1 = lda.coef_[0][0]\n",
    "lda_cutoff = -beta_0 / beta_1\n",
    "\n",
    "print(f\"Logistic regression cutoff: {lr_cutoff}\")\n",
    "print(f\"SVC cutoff: {svm_cutoff}\")\n",
    "print(f\"LDA cutoff: {lda_cutoff}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The decision boundary for Logistic Regression is 239.35, for SVC it is 243.0, and for LDA it is 239.699. Certain models have higher cutoffs than others because they are more sensitive to the data and so the decision boundary is more influenced by the data. For LR, it is sensitive to all data leading to that cutoff. SVC focuses on maximizing the margin between the 2 at risk classes which leads to a higher cutoff. LDA is was closer to LR because it took into consideration overall distribution of data rather than subset of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Write code to implement gradient descent for the SVC estimation for the Heart Attack Risk dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(X, y, lam, eta, epochs):\n",
    "    n, m = X.shape\n",
    "    w = np.zeros(m)\n",
    "    c = 0\n",
    "    for _ in range(epochs):\n",
    "        # Compute gradients\n",
    "        grad_w = -2 * X.T.dot(y - X.dot(w) - c) + 2 * lam * w\n",
    "        grad_c = -2 * np.sum(y - X.dot(w) - c)\n",
    "        # Update parameters\n",
    "        w -= eta * grad_w\n",
    "        c -= eta * grad_c\n",
    "    return np.append(c, w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Write code to implement LDA for the Heart Attach Risk dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lda(X, y):\n",
    "    n, m = X.shape\n",
    "    mu = np.mean(X, axis=0)\n",
    "    X0 = X[y == 0]\n",
    "    X1 = X[y == 1]\n",
    "    mu0 = np.mean(X0, axis=0)\n",
    "    mu1 = np.mean(X1, axis=0)\n",
    "    S0 = (X0 - mu0).T.dot(X0 - mu0)\n",
    "    S1 = (X1 - mu1).T.dot(X1 - mu1)\n",
    "    S = S0 + S1\n",
    "    w = np.linalg.inv(S).dot(mu1 - mu0)\n",
    "    c = w.dot((mu0 + mu1) / 2)\n",
    "    return np.append(c, w)\n",
    "\n",
    "def lda_predict(X, c, w):\n",
    "    return np.where(X.dot(w) + c > 0, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Separate the Heart Attack Risk dataset in half into one training and one test set. Use all three of your model implementations (SCV, LDA, and Logistic Regression) to fit on the training data and predict on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic regression\n",
    "\n",
    "def sigmoid(t):\n",
    "    return 1 / (1 + np.exp(-t))\n",
    "\n",
    "def log_reg(X, y, lam, eta, epochs):\n",
    "    n, m = X.shape\n",
    "    w = np.zeros(m)\n",
    "    c = 0\n",
    "    for _ in range(epochs):\n",
    "        # Compute gradients\n",
    "        grad_w = -2 * X.T.dot(y - sigmoid(X.dot(w) + c)) + 2 * lam * w\n",
    "        grad_c = -2 * np.sum(y - sigmoid(X.dot(w) + c))\n",
    "        # Update parameters\n",
    "        w -= eta * grad_w\n",
    "        c -= eta * grad_c\n",
    "    return np.append(c, w)\n",
    "\n",
    "def log_reg_predict(X, c, w):\n",
    "    return np.where(sigmoid(X.dot(w) + c) > 0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "data = pd.read_csv(\"./heart_attack_clean.csv\")\n",
    "X = data.drop(columns=[\"output\"])\n",
    "y = data[\"output\"]\n",
    "\n",
    "# Split data into training and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)\n",
    "\n",
    "# Fit models\n",
    "svm_betas = gradient_descent(X_train.to_numpy(), y_train.to_numpy(), 0.1, 0.0001, 5000)\n",
    "lda_betas = lda(X_train.to_numpy(), y_train.to_numpy())\n",
    "log_reg_betas = log_reg(X_train.to_numpy(), y_train.to_numpy(), 0.1, 0.0001, 5000)\n",
    "\n",
    "# Predict\n",
    "svm_pred = np.where(X_test.to_numpy().dot(svm_betas[1:]) + svm_betas[0] > 0, 1, 0)\n",
    "lda_pred = lda_predict(X_test.to_numpy(), lda_betas[0], lda_betas[1:])\n",
    "log_reg_pred = log_reg_predict(X_test.to_numpy(), log_reg_betas[0], log_reg_betas[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Give the *accuracy, precision, recall, F1 Score,* and *ROC-AUC* on the test data for all three models. Discuss the results a bit–were there any major differences?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC:\n",
      "Accuracy: 0.5985401459854015\n",
      "Precision: 0.5793650793650794\n",
      "Recall: 0.9733333333333334\n",
      "F1 Score: 0.7263681592039802\n",
      "ROC-AUC: 0.5\n",
      "\n",
      "LDA:\n",
      "Accuracy: 0.5474452554744526\n",
      "Precision: 0.5474452554744526\n",
      "Recall: 1.0\n",
      "F1 Score: 0.7075471698113208\n",
      "ROC-AUC: 0.5\n",
      "\n",
      "Logistic Regression:\n",
      "Accuracy: 0.7153284671532847\n",
      "Precision: 0.75\n",
      "Recall: 0.72\n",
      "F1 Score: 0.7346938775510204\n",
      "ROC-AUC: 0.5\n"
     ]
    }
   ],
   "source": [
    "# 4. Give the *accuracy, precision, recall, F1 Score,* and *ROC-AUC* on the test data for all three models. Discuss the results a bit–were there any major differences?\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    return np.mean(y_true == y_pred)\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    tp = np.sum((y_true == 1) & (y_pred == 1))\n",
    "    fp = np.sum((y_true == 0) & (y_pred == 1))\n",
    "    return tp / (tp + fp)\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    tp = np.sum((y_true == 1) & (y_pred == 1))\n",
    "    fn = np.sum((y_true == 1) & (y_pred == 0))\n",
    "    return tp / (tp + fn)\n",
    "\n",
    "def f1_score(y_true, y_pred):\n",
    "    prec = precision(y_true, y_pred)\n",
    "    rec = recall(y_true, y_pred)\n",
    "    return 2 * prec * rec / (prec + rec)\n",
    "\n",
    "\n",
    "def calculate_roc_auc(y_true, y_scores):\n",
    "    import matplotlib.pyplot as plt\n",
    "    thresholds = np.sort(np.unique(y_scores))\n",
    "    tpr_list = []\n",
    "    fpr_list = []\n",
    "    P = np.sum(y_true == 1)\n",
    "    N = np.sum(y_true == 0)\n",
    "    # Initializations\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    tpr_list.append(0)\n",
    "    fpr_list.append(0)\n",
    "    \n",
    "    # Calculating the rates for each threshold\n",
    "    for t in thresholds:\n",
    "        TP += np.sum((y_scores >= t) & (y_true == 1))\n",
    "        FP += np.sum((y_scores >= t) & (y_true == 0))\n",
    "        tpr = TP / P\n",
    "        fpr = FP / N\n",
    "        \n",
    "        tpr_list.append(tpr)\n",
    "        fpr_list.append(fpr)\n",
    "    tpr_list.append(1)\n",
    "    fpr_list.append(1)\n",
    "\n",
    "    # Area under the ROC curve\n",
    "    tpr_list = np.array(tpr_list)\n",
    "    fpr_list = np.array(fpr_list)\n",
    "    auc = np.trapz(tpr_list, fpr_list)\n",
    "\n",
    "    return auc\n",
    "\n",
    "print(\"SVC:\")\n",
    "print(f\"Accuracy: {accuracy(y_test, svm_pred)}\")\n",
    "print(f\"Precision: {precision(y_test, svm_pred)}\")\n",
    "print(f\"Recall: {recall(y_test, svm_pred)}\")\n",
    "print(f\"F1 Score: {f1_score(y_test, svm_pred)}\")\n",
    "print(f\"ROC-AUC: {calculate_roc_auc(y_test, svm_pred)}\")\n",
    "print()\n",
    "print(\"LDA:\")\n",
    "print(f\"Accuracy: {accuracy(y_test, lda_pred)}\")\n",
    "print(f\"Precision: {precision(y_test, lda_pred)}\")\n",
    "print(f\"Recall: {recall(y_test, lda_pred)}\")\n",
    "print(f\"F1 Score: {f1_score(y_test, lda_pred)}\")\n",
    "print(f\"ROC-AUC: {calculate_roc_auc(y_test, lda_pred)}\")\n",
    "print()\n",
    "print(\"Logistic Regression:\")\n",
    "print(f\"Accuracy: {accuracy(y_test, log_reg_pred)}\")\n",
    "print(f\"Precision: {precision(y_test, log_reg_pred)}\")\n",
    "print(f\"Recall: {recall(y_test, log_reg_pred)}\")\n",
    "print(f\"F1 Score: {f1_score(y_test, log_reg_pred)}\")\n",
    "print(f\"ROC-AUC: {calculate_roc_auc(y_test, log_reg_pred)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From these results it seems there is major differences between the models. In terms of accuracy, Logistic Regression performed the best with 71.53% accuracy. However, SVC had the highest recall at 97.33% but the lowest accuracy at 59.85%. LDA had the lowest accuracy at 54.74% but the highest precision at 54.74%. The ROC-AUC for all models was 0.5 which means that the models are doing moderate for distinguishing between the classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section C\n",
    "\n",
    "In the following questions, consider three model types for classification Logistic Regression, LDA, and SVC.\n",
    "\n",
    "1. Consider the setup of the model and loss function that is used to justify the choice of linear classifier. Which of the three models has the strongest (i.e. most narrow/specific) assumptions? Which of the models requires the least strong assumptions? Explain your answer.\n",
    "    - LDA has the strongest assumptions because it assumes that the features of each class are normally distributed, there is homoscedasticity, and that the boundary between classes is linear. Logistic regression has less stronger assumptions because it assumes that there is no multicollinearity, independence, and that there is linearity between the features and the log-odds. SVC has the least strong assumptions because different kernels can be used if the linear assumption does not hold. Also SVC does not assume any distribution of the data.\n",
    "\n",
    "2. Of the three models, which ones require complex computation “tricks” like Gradient Descent? Which ones have a closed-form solution?\n",
    "    - Logistic Regression and SVC require complex computation tricks like Gradient Descent, however LDA has a closed-form solution and does not require any iterative computations.\n",
    "\n",
    "3. Which of the models would you expect to perform well in very high dimensional and/or linearly dependent data? Which would you expect to perform poorly? Why?\n",
    "    - SVC would perform well for high dimensional data since the the kernel aspect can handle the complex relationships in the data. It can also handle multicollinearity but probability at the cost of efficiency. Logistic regression could handle the high dimensional data but with regularization, since without it it would degrade in performance with multicollinearity. LDA would perform poorly in high dimensional data because it assumes that the features are normally distributed and that the boundary between classes is linear. It also relies on a covariance matrix which can be computationally expensive when the data is high dimensional. it also struggles with linearly dependent features, due to the assumption of normality.\n",
    "\n",
    "4. Suggest an approach (i.e., state a loss function or describe a procedure) to handle high dimensional data in each of the three model.\n",
    "    - For LDA, since it requires a covariance matrix, which can be computationally expensive, we can regularize the covariance matrix through regularization. Having a parameter that controls the regularization can be chosen from cross-validation. For logistic regression, as I said in (3), applying a regularization term such as L1 or L2 can help with multicollinearity as well as penalize large coefficients, so that way the model's complexity is controlled. For SVC, as we learned in class the kernel trick can be used to handle high dimensional data. Using linear kernels can help with linearly dependent data and using other kernels can help with non-linear data. Even using dimensionality reduction techniques such as Principal Component Analysis can help with high dimensional data.\n",
    "\n",
    "5. Which model would you do you prefer for the heart risk classification problem? Why? Why do you think that model lent itself well to this particular data?\n",
    "    - I would prefer logistic regression because of 3 things: interpretability, good performance in this data dimension, and it is designed for binary classification problems such as this. Logistic regression lent it self well to this data because it is a binary classification problem and the data is not high dimensional. The data is also not linearly dependent so the linear assumption is not a problem. It was ultimately more flexible than LDA, since it does not assume normality of the data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
